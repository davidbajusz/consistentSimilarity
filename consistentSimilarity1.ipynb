{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [11:36:32] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics as sklm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base directory here\n",
    "basedir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDKit object to provide the molecules one-by-one on request, plug in your molecular library in Smiles/SDF/etc.\n",
    "library = Chem.SmilesMolSupplier(basedir+'.smiles', delimiter='\\t', titleLine=False)\n",
    "\n",
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "# Determine library smiles, please adjust this when using multi-line file formats\n",
    "library_size = file_len(basedir+'.smiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "# Fingerprint settings\n",
    "radius = 4\n",
    "bits = 1024\n",
    "\n",
    "results = []\n",
    "\n",
    "# Plug in the number of repetitions (no. of reference molecules in the range function)\n",
    "for iteration in range(10):\n",
    "    # Draw molecule randomly from *library*\n",
    "    reference = library[random.randint(0, library_size)]\n",
    "    \n",
    "    refname = reference.GetProp('_Name')\n",
    "    \n",
    "    reference_nheavy = reference.GetNumHeavyAtoms()\n",
    "    \n",
    "    # Generate Morgan (ECFP-like) fingerprints\n",
    "    fpref = AllChem.GetMorganFingerprintAsBitVect(reference,radius,nBits=bits)\n",
    "    \n",
    "    # Size expressed by the norm is the number of On bits\n",
    "    reference_size = fpref.GetNumOnBits()\n",
    "    \n",
    "    for j in range(100):\n",
    "        \n",
    "        query = library[random.randint(0, library_size)]\n",
    "        \n",
    "        queryname = query.GetProp('_Name')\n",
    "        \n",
    "        query_nheavy = query.GetNumHeavyAtoms()\n",
    "        \n",
    "        fpquery = AllChem.GetMorganFingerprintAsBitVect(query,radius,nBits=bits)\n",
    "        \n",
    "        query_size = fpquery.GetNumOnBits()\n",
    "        \n",
    "        commonOnbits = len([i for i in fpref.GetOnBits() if i in fpquery.GetOnBits()])\n",
    "        \n",
    "        euclidean = math.sqrt( reference_size + query_size - 2*commonOnbits )\n",
    "        \n",
    "        tanimoto = DataStructs.FingerprintSimilarity(fpref,fpquery)\n",
    "        \n",
    "        # Write out molecule names, sizes in nheavy and norm, Tanimoto and Euclidean\n",
    "        results.append([refname,queryname,reference_nheavy,query_nheavy,\n",
    "                        reference_size,query_size,tanimoto,euclidean])\n",
    "\n",
    "# Convert to pandas DataFrame and write to file\n",
    "df = pd.DataFrame(results, columns=['reference','query','reference_nheavy','query_nheavy',\n",
    "                           'reference_size','query_size','tanimoto','euclidean'])\n",
    "df.to_excel(basedir+'primary_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# Split to smaller tables per reference molecule\n",
    "for ref in df['reference'].unique():\n",
    "    subdf = df[df.reference == ref]\n",
    "    \n",
    "    # Iterate over each pair of query molecules\n",
    "    for iteration,i in enumerate(subdf.index):\n",
    "        rowi = subdf.loc[i]\n",
    "        for j in subdf.index[iteration+1:]:\n",
    "            \n",
    "            rowj = subdf.loc[j]\n",
    "            \n",
    "            # Calculate differences moving from molecule i to j\n",
    "            delta_size = rowj['query_size']-rowi['query_size']\n",
    "            deltaT = rowj['tanimoto']-rowi['tanimoto']\n",
    "            deltaE = rowj['euclidean']-rowi['euclidean']\n",
    "            \n",
    "            # If the size and Euclidean distance change in the same direction (bigger size results in bigger distance),\n",
    "            # then *smaller_is_more_similar* is True. The product of the signs can be zero as well, in that case\n",
    "            # *smaller_is_more_similar* is also True.\n",
    "            if np.sign(deltaE) * np.sign(delta_size) != -1.0:\n",
    "                smaller_is_more_similar = True\n",
    "            else:\n",
    "                smaller_is_more_similar = False\n",
    "            \n",
    "            # If the change of Tanimoto and Euclidean is in the opposite direction (bigger Tanimoto similarity goes\n",
    "            # together with smaller Euclidean distance), then *consistent* is True. Also True when the product is zero.\n",
    "            if np.sign(deltaE) * np.sign(deltaT) != 1.0:\n",
    "                consistent = True\n",
    "            else:\n",
    "                consistent = False\n",
    "            \n",
    "            results.append([delta_size,deltaT,deltaE,smaller_is_more_similar,consistent])\n",
    "# Convert to pandas DataFrame and write to file\n",
    "resultsdf = pd.DataFrame(results, columns=['delta_size','deltaT','deltaE','smaller_is_more_similar','consistent'])\n",
    "resultsdf.to_excel(basedir+'comparisons.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check confusion matrix and write to file\n",
    "conf = sklm.confusion_matrix(resultsdf['smaller_is_more_similar'],resultsdf['consistent'])\n",
    "\n",
    "index = pd.MultiIndex.from_tuples([('smaller_is_more_similar','False'),('smaller_is_more_similar','True')])\n",
    "columns = pd.MultiIndex.from_tuples([('consistent','False'),('consistent','True')])\n",
    "confmatrix = pd.DataFrame(conf, index=index, columns=columns)\n",
    "\n",
    "confmatrix.to_excel(basedir+'confusion_matrix.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
